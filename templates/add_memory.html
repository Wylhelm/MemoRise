{% extends "base.html" %}

{% block content %}
<h1>Add Memory</h1>
<form method="POST">
    <div class="form-group">
        <label for="content">Memory Content:</label>
        <textarea class="form-control" id="content" name="content" rows="3" required></textarea>
    </div>
    <button type="submit" class="btn btn-primary">Add Memory</button>
</form>
<hr>
<h2>Add Voice Memory</h2>
<button id="startRecording" class="btn btn-success">Start Recording</button>
<button id="stopRecording" class="btn btn-danger" style="display: none;">Stop Recording</button>
<p id="recordingStatus"></p>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script>
    $(document).ready(function() {
        let mediaRecorder;
        let audioChunks = [];
        let silenceTimer;
        const silenceThreshold = 2000; // 2 seconds of silence

        $("#startRecording").click(function() {
            console.log("Start recording button clicked");
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    console.log("Audio stream obtained");
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();

                    console.log("Recording started");
                    $("#recordingStatus").text("Recording... (Will stop automatically after 2 seconds of silence)");

                    mediaRecorder.addEventListener("dataavailable", event => {
                        console.log("Data available event triggered");
                        audioChunks.push(event.data);
                        resetSilenceTimer();
                    });

                    $("#startRecording").hide();
                    $("#stopRecording").show();

                    // Set up audio analysis for silence detection
                    const audioContext = new AudioContext();
                    const analyser = audioContext.createAnalyser();
                    const microphone = audioContext.createMediaStreamSource(stream);
                    microphone.connect(analyser);
                    analyser.fftSize = 2048;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);

                    function checkSilence() {
                        analyser.getByteFrequencyData(dataArray);
                        const sum = dataArray.reduce((a, b) => a + b, 0);
                        const average = sum / bufferLength;
                        console.log("Average audio level:", average);
                        
                        if (average < 10) { // Adjust this threshold as needed
                            console.log("Silence detected");
                            resetSilenceTimer();
                        }
                    }

                    function resetSilenceTimer() {
                        clearTimeout(silenceTimer);
                        silenceTimer = setTimeout(stopRecording, silenceThreshold);
                    }

                    // Start checking for silence
                    setInterval(checkSilence, 100);
                })
                .catch(error => {
                    console.error("Error accessing microphone:", error);
                    $("#recordingStatus").text("Error: Unable to access microphone. Please check your browser settings.");
                    $("#recordingStatus").removeClass("text-success").addClass("text-danger");
                });
        });

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
                console.log("Recording stopped");
                $("#startRecording").show();
                $("#stopRecording").hide();
                $("#recordingStatus").text("Processing...");

                mediaRecorder.addEventListener("stop", () => {
                    console.log("MediaRecorder stopped event triggered");
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    console.log("Audio blob created, size:", audioBlob.size, "bytes");
                    const formData = new FormData();
                    formData.append("audio", audioBlob, "recording.wav");

                    $.ajax({
                        url: "{{ url_for('add_voice_memory') }}",
                        type: "POST",
                        data: formData,
                        processData: false,
                        contentType: false,
                        success: function(response) {
                            console.log("Server response:", response);
                            if (response.success) {
                                $("#recordingStatus").text(response.message);
                                $("#recordingStatus").removeClass("text-danger").addClass("text-success");
                            } else {
                                $("#recordingStatus").text("Error: " + response.message);
                                $("#recordingStatus").removeClass("text-success").addClass("text-danger");
                            }
                        },
                        error: function(jqXHR, textStatus, errorThrown) {
                            console.error("AJAX Error:", textStatus, errorThrown);
                            $("#recordingStatus").text("An error occurred while processing the voice memory. Please check the console for details.");
                            $("#recordingStatus").removeClass("text-success").addClass("text-danger");
                        }
                    });

                    audioChunks = [];
                });
            }
        }

        $("#stopRecording").click(stopRecording);
    });
</script>
{% endblock %}
